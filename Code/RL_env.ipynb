{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PriceModel():\n",
    "    '''\n",
    "    Note:This is a stateless class, gathering price evolution models in one place\n",
    "    '''\n",
    "    def price_model_1(current_price, current_action, tau, vol_matrix, perm_impact_matrix, random_vector):\n",
    "        return current_price + (tau**0.5) * (vol_matrix@(random_vector)) - perm_impact_matrix@current_action\n",
    "    def price_model_2(current_price):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import pandas as pd\n",
    "\n",
    "class LiquidationEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_assets=3, \n",
    "                 initial_shares=100, \n",
    "                 initial_prices=100, \n",
    "                 max_steps=5,\n",
    "                 price_model=PriceModel,\n",
    "                 tau = 1,\n",
    "                 temp_price_matrix = np.identity(3),\n",
    "                 vol_matrix = np.identity(3),\n",
    "                 perm_impact_matrix = np.identity(3)\n",
    "                 ):\n",
    "        super(LiquidationEnv, self).__init__()\n",
    "        \n",
    "        # Environment parameters\n",
    "        self.n_assets = n_assets\n",
    "        self.initial_shares = np.full(n_assets, initial_shares, dtype=np.float32)\n",
    "        self.initial_prices = np.full(n_assets, initial_prices, dtype=np.float32)\n",
    "        self.max_steps = max_steps\n",
    "        self.price_generator = price_model.price_model_1\n",
    "        self.temp_price_matrix = temp_price_matrix\n",
    "        self.tau = tau\n",
    "        self.vol_matrix = vol_matrix\n",
    "        self.perm_impact_matrix = perm_impact_matrix\n",
    "        \n",
    "        # Define action and observation spaces\n",
    "        self.action_space = spaces.Box(\n",
    "            low=0,\n",
    "            high= 1,\n",
    "            shape=(n_assets,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"prices\": spaces.Box(low = -np.inf, high=np.inf, shape=(n_assets,), dtype=np.float32),\n",
    "            \"remaining\": spaces.Box(low = 0, high=initial_shares, shape=(n_assets,), dtype=np.float32),\n",
    "            \"acc_revenue\": spaces.Box(low = -np.inf, high=np.inf, shape=(1,), dtype=np.float32)\n",
    "        })\n",
    "        \n",
    "        # Initialize state\n",
    "        self.state = None\n",
    "        self.current_step = 0\n",
    "        self.reset()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return {\n",
    "            \"prices\": self.state['prices'].copy().astype(np.float32),\n",
    "            \"remaining\": self.state['remaining'].copy().astype(np.float32),\n",
    "            \"acc_revenue\": np.array([self.state['acc_revenue']], dtype=np.float32)\n",
    "        }\n",
    "\n",
    "    def _next_price(self, current_price , current_action, tau, vol_matrix, perm_impact_matrix, random_vector):\n",
    "        # actual_action = self.state['remaining'] * current_action\n",
    "        return self.price_generator(current_price, current_action, tau, vol_matrix, perm_impact_matrix, random_vector)\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset initial prices (customize with your price initialization)\n",
    "        self.state = {\n",
    "            'prices': self.initial_prices.copy(),\n",
    "            'remaining': self.initial_shares.copy(),\n",
    "            'acc_revenue': 0.0\n",
    "        }\n",
    "        self.current_step = 0\n",
    "        return self._get_obs()\n",
    "    \n",
    "    def _get_reward(self, state, action, temp_price_matrix):\n",
    "        '''\n",
    "        The function to calculate the reward\n",
    "        '''\n",
    "        # actual_action = action * state['remaining']\n",
    "        reward = action.dot(state['prices'] - temp_price_matrix.dot(action))\n",
    "        return reward\n",
    "\n",
    "    def step(self, action):\n",
    "        # TODO: need a better way than clipping\n",
    "        actual_action = self.state['remaining'] * action\n",
    "        reward = self._get_reward(self.state, actual_action, self.temp_price_matrix)\n",
    "        \n",
    "        # Update state\n",
    "        self.state['remaining'] -= actual_action\n",
    "        random_vector = np.random.normal(size = self.n_assets)\n",
    "        self.state['prices'] = self._next_price(self.state['prices'] , actual_action, self.tau, self.vol_matrix, self.perm_impact_matrix, random_vector)\n",
    "        step_revenue = np.sum(actual_action * (self.state['prices'] - self.temp_price_matrix.dot(actual_action))) # Calculate revenue from current prices\n",
    "        self.state['acc_revenue'] += step_revenue # TODO: what's the third part of the state? what's the formulor to calculate it?\n",
    "        \n",
    "        # Update step counter\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        # Check termination conditions\n",
    "        done = (np.sum(self.state['remaining']) <= 0) or (self.current_step >= self.max_steps)\n",
    "        if done:\n",
    "            reward = 0.\n",
    "            \n",
    "        \n",
    "        return self._get_obs(), reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        print(f\"Step: {self.current_step}\")\n",
    "        print(f\"Prices: {self.state['prices']}\")\n",
    "        print(f\"Remaining: {self.state['remaining']}\")\n",
    "        print(f\"Accumulated Revenue: {self.state['acc_revenue']:.2f}\\n\")\n",
    "        \n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.84     |\n",
      "|    ep_rew_mean     | 3.51e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 5906     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x734887f78df0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Create environment\n",
    "env = LiquidationEnv(n_assets=3, initial_shares=100)\n",
    "#env.render()\n",
    "# Verify environment compatibility\n",
    "# check_env(env)\n",
    "\n",
    "# Create and train model\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps = 50)\n",
    "\n",
    "# # Test trained model\n",
    "# obs = env.reset()\n",
    "# for _ in range(100):\n",
    "\n",
    "# if done:\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Create environment\n",
    "env = LiquidationEnv(n_assets=3, initial_shares=100)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0\n",
      "Prices: [100. 100. 100.]\n",
      "Remaining: [100. 100. 100.]\n",
      "Accumulated Revenue: 0.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Step: 8\n",
      "Prices: [92.45442804 97.5168319  93.08483972]\n",
      "Remaining: [92.27447 92.27447 92.27447]\n",
      "Accumulated Revenue: 2224.51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = np.ones(3)*0.01\n",
    "obs, rewards, done, info = env.step(action)\n",
    "print(done)\n",
    "env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
